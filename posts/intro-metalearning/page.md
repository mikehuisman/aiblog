<title>AI Blog</title>

## Introduction to Meta-Learning

The wish to build Artificial Intelligence (AI) dates back hundreds of years ago. With the rise of computers, this wish has become absolute reality, although one could philosophize about when we can call something intelligent. AI researchers are known to be especially pessimistic: after solving a difficult problem that seemed to require intelligence, they suddenly seem to change their minds. "I solved this problem! But the algorithm does simply this and that... That is not intelligent!". We are less pessimistic, and argue that any program that produces behavior that would otherwise require human intelligence, can be called an AI, following one of the definitions in [Russel and Norvig](http://aima.cs.berkeley.edu/).

Looking back, it seems like the field of AI has grown in distinct stages. At the start, we explicitly wrote instructions to computers to perform certain tasks (e.g., write a search algorithm to play chess). This approach was successful to some extent (e.g., deep blue won from Kasparov at chess), but is not very flexible, as we can only solve tasks for which we can develop explicit procedures. As it turns out, there are many tasks for which it is extremely difficult to write these procedures! Think about all the things that humans do on a daily basis: recognizing faces, moving and navigating in the world, and making complex decisions. 

Due to these limitations, the field of AI has evolved. Instead of explicitly programming computers to do tasks, the idea is to write programs that can learn how to do tasks themselves! 

This strategy has completely changed, as we now write programs (e.g., neural networks) that learn how to perform tasks! The latter development has significantly eased the task of programming, as we no longer need to tell the computer explicitly what to do in order to do well at a certain task. Additionally, these learning programs can even solve tasks that almost no human being would be able to program by hand (e.g., face recognition)!
However, there are some limitations of this approach. One of them is that the learning algorithm is fixed up-front. Moreover, neural networks, which are highly successful, seem to require lots of data and computational resources. 

It seems like we are 

